{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Algorithm の選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 余分な Warning を非表示にする\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Library の Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# matplotlib 日本語化対応\n",
    "import japanize_matplotlib\n",
    "\n",
    "# 表示 Option の調整\n",
    "np.set_printoptions(suppress=True, precision=4)  # NumPy の浮動小数点の表示精度\n",
    "pd.options.display.float_format = '{:.4f}'.format  # pandas での浮動小数点の表示精度\n",
    "pd.set_option('display.max_columns', None)  # DataFrame ですべての項目を表示\n",
    "plt.rcParams['font.size'] = 14  # Graph の Default font 指定\n",
    "random_seed = 123  # 乱数の種"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(512, 30)\n",
      "(57, 30)\n"
     ]
    }
   ],
   "source": [
    "# Sample data の読み込み\n",
    "# （乳がん疾患 Data）\n",
    "\n",
    "# Data の load\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# 入力 Data: x(30次元)\n",
    "# 正解 Data: y\n",
    "x = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Sample data の分割\n",
    "\n",
    "# Data 分割の Parameters\n",
    "test_size = 0.1\n",
    "\n",
    "# Data 分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_seed, stratify=y)\n",
    "\n",
    "# 分割 Size 確認\n",
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 複数 Algorithm の List を作成"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 複数 Algorithm で精度を比較\n",
    "# 結果が同じになるよう random_state は同一にする\n",
    "\n",
    "# 線形回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "algorithm = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "# Support vector machine(Kernel)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "algorithm2 = SVC(kernel='rbf', random_state=random_seed)\n",
    "\n",
    "# 決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "algorithm3 = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "algorithm4 = RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "algorithm5 = XGBClassifier(random_state=random_seed)\n",
    "\n",
    "# Algorithm の List 作成\n",
    "algorithms = [algorithm, algorithm2, algorithm3, algorithm4, algorithm5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9474 LogisticRegression\n",
      "score: 0.8947 SVC\n",
      "score: 0.9474 DecisionTreeClassifier\n",
      "score: 0.9298 RandomForestClassifier\n",
      "[05:18:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "score: 0.9825 XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "# 複数 Algorithm で精度比較\n",
    "for algorithm in algorithms:\n",
    "    # 訓練 Data で学習\n",
    "    algorithm.fit(x_train, y_train)\n",
    "    # 検証 Data で精度測定\n",
    "    score = algorithm.score(x_test, y_test)\n",
    "    # Algorithm 名取得\n",
    "    name = algorithm.__class__.__name__\n",
    "    # 精度と Algorithm 名表示\n",
    "    print(f'score: {score:.4f} {name}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Support Vector Machine は、精度が悪い\n",
    "- XGBoost は精度が良く検証 Data に対して98.25% となっている\n",
    "- 他の３つの候補は似たり寄ったりだが、Logistic 回帰と決定木の精度が Random Forest よりは良い。\n",
    "\n",
    "この見た目の結論は、本当に正しいのか？"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyper Parameters の最適化\n",
    "### Support Vector Machine の Parameters 値\n",
    "- gamma: 'scale'\n",
    "- C: 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.6316 gamma: 1\n",
      "score: 0.6316 gamma: 0.1\n",
      "score: 0.6316 gamma: 0.01\n",
      "score: 0.9474 gamma: 0.001\n",
      "score: 0.9474 gamma: 0.0001\n",
      "score: 0.9474 gamma: 1e-05\n"
     ]
    }
   ],
   "source": [
    "# gamma の最適化\n",
    "gammas = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "for gamma in gammas:\n",
    "    algorithm = SVC(kernel='rbf', gamma=gamma, random_state=random_seed)\n",
    "    algorithm.fit(x_train, y_train)\n",
    "    score = algorithm.score(x_test, y_test)\n",
    "    print(f'score: {score:.4f} gamma: {gamma}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "上記の結果から、0.001 を採用。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### gamma の tuning 方法\n",
    "１を出発点に、順に 1/10 倍して値を小さくし、最適な値を見つける。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9474 C: 1\n",
      "score: 0.9298 C: 10\n",
      "score: 0.9298 C: 100\n",
      "score: 0.9298 C: 1000\n",
      "score: 0.9298 C: 10000\n"
     ]
    }
   ],
   "source": [
    "# C の最適化\n",
    "# gamma は、先ほど調べた最適値 0.001 を採用\n",
    "\n",
    "Cs = [1, 10, 100, 1000, 10000]\n",
    "for C in Cs:\n",
    "    algorithm  = SVC(kernel='rbf', gamma=0.001, C=C, random_state=random_seed)\n",
    "    algorithm.fit(x_train, y_train)\n",
    "    score = algorithm.score(x_test, y_test)\n",
    "    print(f'score: {score:.4f} C: {C}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "C 値に関しては、 Default 値の１が最適であることを確認。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### C 値の tuning 方法\n",
    "Default 値の１を出発点に、10倍ずつしていって最適値を求める。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 公差検定法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均 Score: 0.9141 個別 Score: [0.8889 0.9181 0.9353]\n"
     ]
    }
   ],
   "source": [
    "# 特定の Algorithm に対して公差検定を実施\n",
    "\n",
    "# Algorithm の定義\n",
    "algorithm = SVC(kernel='rbf', random_state=random_seed, gamma=0.001, C=1)\n",
    "\n",
    "# 分割時に正解 Data の分布が偏らないように StratifiedKFold を利用\n",
    "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# 公差検定の実施（分割数=3）\n",
    "scores = cross_val_score(algorithm, x_train, y_train, cv=stratifiedkfold)\n",
    "\n",
    "# 平均値の計算\n",
    "mean = scores.mean()\n",
    "\n",
    "# 結果表示\n",
    "print(f'平均 Score: {mean:.4f} 個別 Score: {scores}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "from sklearn.model_selection import cross_val_score\n",
    "```\n",
    "scikit-learn の cross_val_score 関数を利用することで公差検定を行なえる。\n",
    "- 引数: algorithm x, y, 分割数 cv を指定\n",
    "- 戻り値: 分割数と同じ要素数の NumPy 配列（※上記では、３つの Score の平均値を mean()関数で求めて合わせて表示）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}